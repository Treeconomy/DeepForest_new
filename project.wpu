#!wing
#!version=7.0
##################################################################
# Wing project file : User-specific branch                       #
##################################################################
[user attributes]
debug.err-values = {loc('../../../../Applications/WingPro.app/Contents/Resources/src/testing/runners/run_pytest_xml.py'): {}}
debug.exceptions-ignored = {loc('../../opt/miniconda3/envs/DeepForest/lib/python3.7/site-packages/_pytest/config/__init__.py'): {1514: True},
                            loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/config/__init__.py'): {1514: True}}
guimgr.overall-gui-state = {'windowing-policy': 'combined-window',
                            'windows': [{'name': 'BeCfPquEZeqQ6pfJCERhTaNA7C'\
        'a3fCTw',
        'size-state': '',
        'type': 'dock',
        'view': {'area': 'tall',
                 'constraint': None,
                 'current_pages': [0,
                                   0],
                 'full-screen': False,
                 'notebook_display': 'normal',
                 'notebook_percent': 0.31092436974789917,
                 'override_title': None,
                 'pagelist': [('project',
                               'tall',
                               0,
                               {'tree-state': {'file-sort-method': 'by name',
        'list-files-first': False,
        'tree-states': {'deep': {'expanded-nodes': [(1,)],
                                 'selected-nodes': [(1,
        7)],
                                 'top-node': (0,)}},
        'tree-style': 'deep'}}),
                              ('browser',
                               'tall',
                               0,
                               {}),
                              ('snippets',
                               'tall',
                               0,
                               {}),
                              ('source-assistant',
                               'tall',
                               2,
                               {}),
                              ('debug-stack',
                               'tall',
                               1,
                               {}),
                              ('indent',
                               'tall',
                               2,
                               {})],
                 'primary_view_state': {'area': 'wide',
        'constraint': None,
        'current_pages': [4,
                          2],
        'notebook_display': 'normal',
        'notebook_percent': 0.565470417070805,
        'override_title': None,
        'pagelist': [('batch-search',
                      'wide',
                      0,
                      {'fScope': {'fFileSetName': 'All Source Files',
                                  'fLocation': None,
                                  'fRecursive': True,
                                  'fType': 'project-files'},
                       'fSearchSpec': {'fEndPos': None,
                                       'fIncludeLinenos': True,
                                       'fInterpretBackslashes': False,
                                       'fMatchCase': False,
                                       'fOmitBinary': True,
                                       'fRegexFlags': 42,
                                       'fReplaceText': u'',
                                       'fReverse': False,
                                       'fSearchText': u'',
                                       'fStartPos': 0,
                                       'fStyle': 'text',
                                       'fWholeWords': False,
                                       'fWrap': True},
                       'fUIOptions': {'fAutoBackground': True,
                                      'fFilePrefix': 'short-file',
                                      'fFindAfterReplace': True,
                                      'fInSelection': False,
                                      'fIncremental': True,
                                      'fReplaceOnDisk': False,
                                      'fShowFirstMatch': False,
                                      'fShowLineno': True,
                                      'fShowReplaceWidgets': False},
                       'replace-entry-expanded': False,
                       'search-entry-expanded': False}),
                     ('interactive-search',
                      'wide',
                      0,
                      {'fScope': {'fFileSetName': 'All Source Files',
                                  'fLocation': None,
                                  'fRecursive': True,
                                  'fType': 'project-files'},
                       'fSearchSpec': {'fEndPos': None,
                                       'fIncludeLinenos': True,
                                       'fInterpretBackslashes': False,
                                       'fMatchCase': False,
                                       'fOmitBinary': True,
                                       'fRegexFlags': 42,
                                       'fReplaceText': u'score_threshold',
                                       'fReverse': False,
                                       'fSearchText': u'evaluate',
                                       'fStartPos': 0,
                                       'fStyle': 'text',
                                       'fWholeWords': False,
                                       'fWrap': True},
                       'fUIOptions': {'fAutoBackground': True,
                                      'fFilePrefix': 'short-file',
                                      'fFindAfterReplace': True,
                                      'fInSelection': False,
                                      'fIncremental': True,
                                      'fReplaceOnDisk': False,
                                      'fShowFirstMatch': False,
                                      'fShowLineno': True,
                                      'fShowReplaceWidgets': False}}),
                     ('debug-data',
                      'wide',
                      0,
                      {}),
                     ('debug-breakpoints',
                      'wide',
                      0,
                      {'tree-state': []}),
                     ('testing',
                      'wide',
                      0,
                      {'added-files': [],
                       'filter': u'',
                       'recent-filters': None,
                       'sort-order': 'source-lineno',
                       'tree-state': {'expanded-nodes': [(3,),
        (3,
         2),
        (3,
         3),
        (3,
         4),
        (3,
         5),
        (3,
         6),
        (3,
         7),
        (3,
         8),
        (3,
         9),
        (3,
         11)],
                                      'selected-nodes': [(3,)],
                                      'top-node': (0,)}}),
                     ('debug-io',
                      'wide',
                      1,
                      {}),
                     ('debug-exceptions',
                      'wide',
                      1,
                      {}),
                     ('debug-probe',
                      'wide',
                      2,
                      {'active-range': (None,
        -1,
        -1),
                       'attrib-starts': [],
                       'code-line': '',
                       'first-line': 1067L,
                       'folded-linenos': [],
                       'history': {u'file:/Applications/WingPro.app/Contents/Resources/src/testing/runners/run_pytest_xml.py': ['i'\
        'mages\n',
        'targets\n',
        '[loss for loss in loss_dict.values()]\n',
        ' loss_dict.values()\n',
        'len(loss_dict)\n',
        'self.backbone.eval\n',
        'loss_dict = self.backbone.forward(images, targets)\n',
        'loss_dict\n',
        'self.backbone\n',
        'self.backbone.training\n',
        'model.training\n',
        'model.device\n',
        'model\n',
        'prediction[0][0]\n',
        'prediction[0]\n',
        'prediction[0].to_device("cpu")\n',
        'prediction\n']},
                       'launch-id': None,
                       'sel-line': 1091L,
                       'sel-line-start': 51110L,
                       'selection_end': 51110L,
                       'selection_start': 51110L,
                       'zoom': 0L}),
                     ('debug-watch',
                      'wide',
                      1,
                      {'node-states': [],
                       'tree-state': {'expanded-nodes': [],
                                      'selected-nodes': [],
                                      'top-node': (0,)}}),
                     ('debug-modules',
                      'wide',
                      1,
                      {}),
                     ('python-shell',
                      'wide',
                      2,
                      {'active-range': (None,
        -1,
        -1),
                       'attrib-starts': [],
                       'code-line': '',
                       'first-line': 0L,
                       'folded-linenos': [],
                       'history': {None: ['import torch\n',
        '"cuda:0" if torch.cuda.is_available() else "cpu"   \n',
        'j{"a":1,"b":2}\n',
        'j={"a":1,"b":2}\n']},
                       'launch-id': None,
                       'sel-line': 12L,
                       'sel-line-start': 387L,
                       'selection_end': 387L,
                       'selection_start': 387L,
                       'zoom': 0L}),
                     ('bookmarks',
                      'wide',
                      1,
                      {}),
                     ('messages',
                      'wide',
                      2,
                      {}),
                     ('os-command',
                      'wide',
                      1,
                      {})],
        'primary_view_state': {'editor_states': ({'bookmarks': ([[loc('deepforest/predict.py'),
        {'attrib-starts': [('predict_image|0|',
                            13)],
         'code-line': '    prediction = model(image)\n',
         'first-line': 11L,
         'folded-linenos': [],
         'sel-line': 26L,
         'sel-line-start': 833L,
         'selection_end': 855L,
         'selection_start': 850L,
         'zoom': 0L},
        1613964176.662392],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.predict_image|0|',
                             68)],
          'code-line': '        return result\n',
          'first-line': 102L,
          'folded-linenos': [],
          'sel-line': 94L,
          'sel-line-start': 3621L,
          'selection_end': 3642L,
          'selection_start': 3642L,
          'zoom': 0L},
         1613964555.592169],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_image|0|',
                             13)],
          'code-line': '    prediction = model(image)\n',
          'first-line': 10L,
          'folded-linenos': [],
          'sel-line': 26L,
          'sel-line-start': 833L,
          'selection_end': 855L,
          'selection_start': 850L,
          'zoom': 0L},
         1613964570.756514],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.predict_image|0|',
                             68)],
          'code-line': '        image = torch.tensor(image, device=self.devi'\
                       'ce).float()        \n',
          'first-line': 121L,
          'folded-linenos': [],
          'sel-line': 91L,
          'sel-line-start': 3400L,
          'selection_end': 3472L,
          'selection_start': 3400L,
          'zoom': 0L},
         1613964591.239704],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_image|0|',
                             13)],
          'code-line': '    prediction = model(image)\n',
          'first-line': 38L,
          'folded-linenos': [],
          'sel-line': 26L,
          'sel-line-start': 833L,
          'selection_end': 855L,
          'selection_start': 850L,
          'zoom': 0L},
         1613964615.587995],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.predict_image|0|',
                             68)],
          'code-line': '        image = torch.tensor(image, device=self.devi'\
                       'ce).float()        \n',
          'first-line': 104L,
          'folded-linenos': [],
          'sel-line': 91L,
          'sel-line-start': 3400L,
          'selection_end': 3472L,
          'selection_start': 3400L,
          'zoom': 0L},
         1613964637.533679],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_tile|0|',
                             85)],
          'code-line': '    reassambles into a single array.\n',
          'first-line': 111L,
          'folded-linenos': [],
          'sel-line': 99L,
          'sel-line-start': 3633L,
          'selection_end': 3669L,
          'selection_start': 3669L,
          'zoom': 0L},
         1613964674.175424],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.predict_image|0|',
                             68)],
          'code-line': '        result = predict.predict_image(model =  self'\
                       '.backbone, image = image, return_plot = return_plot,'\
                       ' score_threshold = score_threshold, device=self.devi'\
                       'ce)\n',
          'first-line': 81L,
          'folded-linenos': [],
          'sel-line': 91L,
          'sel-line-start': 3400L,
          'selection_end': 3558L,
          'selection_start': 3558L,
          'zoom': 0L},
         1613964686.289449],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_file|0|',
                             48)],
          'code-line': '        \n',
          'first-line': 67L,
          'folded-linenos': [],
          'sel-line': 76L,
          'sel-line-start': 2693L,
          'selection_end': 2701L,
          'selection_start': 2701L,
          'zoom': 0L},
         1613965201.168354],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.predict_image|0|',
                             68)],
          'code-line': '        result = predict.predict_image(model =  self'\
                       '.backbone, image = image, return_plot = return_plot,'\
                       ' score_threshold = score_threshold, device=self.devi'\
                       'ce)\n',
          'first-line': 81L,
          'folded-linenos': [],
          'sel-line': 91L,
          'sel-line-start': 3400L,
          'selection_end': 3558L,
          'selection_start': 3558L,
          'zoom': 0L},
         1613965201.182599],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.validation_step|0|',
                             199)],
          'code-line': '        \n',
          'first-line': 220L,
          'folded-linenos': [],
          'sel-line': 213L,
          'sel-line-start': 8569L,
          'selection_end': 8577L,
          'selection_start': 8577L,
          'zoom': 0L},
         1613965647.217671],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.create_model|0|',
                             59)],
          'code-line': '        #Load on GPU is available\n',
          'first-line': 56L,
          'folded-linenos': [],
          'sel-line': 63L,
          'sel-line-start': 2108L,
          'selection_end': 2141L,
          'selection_start': 2141L,
          'zoom': 0L},
         1613965764.015882],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_train_validation_step|0|',
                             43)],
          'code-line': 'def test_train_validation_step(m):    \n',
          'first-line': 33L,
          'folded-linenos': [],
          'sel-line': 43L,
          'sel-line-start': 871L,
          'selection_end': 909L,
          'selection_start': 871L,
          'zoom': 0L},
         1613965764.061003],
        [loc('tests/test_main.py'),
         {'attrib-starts': [('test_train_validation_step|0|',
                             43)],
          'code-line': '    trainer.fit(m, train_ds, train_ds)\n',
          'first-line': 37L,
          'folded-linenos': [],
          'sel-line': 48L,
          'sel-line-start': 1091L,
          'selection_end': 1129L,
          'selection_start': 1091L,
          'zoom': 0L},
         1613965773.197468],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_file|0|',
                             48)],
          'code-line': '        \n',
          'first-line': 67L,
          'folded-linenos': [],
          'sel-line': 76L,
          'sel-line-start': 2693L,
          'selection_end': 2701L,
          'selection_start': 2701L,
          'zoom': 0L},
         1613965773.209054],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_file|0|',
                             48)],
          'code-line': '        image = torch.tensor(image, device=device).f'\
                       'loat()                \n',
          'first-line': 180L,
          'folded-linenos': [],
          'sel-line': 73L,
          'sel-line-start': 2570L,
          'selection_end': 2637L,
          'selection_start': 2637L,
          'zoom': 0L},
         1613965942.071056],
        [loc('deepforest/main.py'),
         {'attrib-starts': [('deepforest|0|',
                             17),
                            ('deepforest|0|.validation_step|0|',
                             198)],
          'code-line': '        return losses\n',
          'first-line': 198L,
          'folded-linenos': [],
          'sel-line': 214L,
          'sel-line-start': 8529L,
          'selection_end': 8550L,
          'selection_start': 8550L,
          'zoom': 0L},
         1613966017.547407],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_file|0|',
                             48)],
          'code-line': '        image = torch.tensor(image, device=device).f'\
                       'loat()                \n',
          'first-line': 180L,
          'folded-linenos': [],
          'sel-line': 73L,
          'sel-line-start': 2570L,
          'selection_end': 2637L,
          'selection_start': 2637L,
          'zoom': 0L},
         1613966017.557494],
        [loc('deepforest/predict.py'),
         {'attrib-starts': [('predict_image|0|',
                             13)],
          'code-line': '    prediction.to_device("cpu")\n',
          'first-line': 17L,
          'folded-linenos': [],
          'sel-line': 30L,
          'sel-line-start': 971L,
          'selection_end': 971L,
          'selection_start': 971L,
          'zoom': 0L},
         1613966186.684823],
        [loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py'),
         {'attrib-starts': [('Module|0|',
                             177),
                            ('Module|0|.__getattr__|0|',
                             764)],
          'code-line': "        raise ModuleAttributeError(\"'{}' object has"\
                       " no attribute '{}'\".format(\n",
          'first-line': 762L,
          'folded-linenos': [],
          'sel-line': 777L,
          'sel-line-start': 32045L,
          'selection_end': 32045L,
          'selection_start': 32045L,
          'zoom': 0L},
         1613966196.453331]],
        20),
        'current-loc': loc('deepforest/predict.py'),
        'editor-state-list': [(loc('../NeonTreeEvaluation/annotations/ABBY_063.xml'),
                               {'attrib-starts': [],
                                'code-line': '    <filename>ABBY_063_2019.ti'\
        'f</filename>\n',
                                'first-line': 0L,
                                'folded-linenos': [],
                                'sel-line': 2L,
                                'sel-line-start': 38L,
                                'selection_end': 65L,
                                'selection_start': 65L,
                                'zoom': 0L}),
                              (loc('../DeepForest_Model/src/crops.py'),
                               {'attrib-starts': [('generate_training|0|',
        113)],
                                'code-line': '    shps_tifs = glob.glob(BASE'\
        '_PATH + dirname + "*.tif")\n',
                                'first-line': 143L,
                                'folded-linenos': [],
                                'sel-line': 139L,
                                'sel-line-start': 6270L,
                                'selection_end': 6319L,
                                'selection_start': 6319L,
                                'zoom': 0L}),
                              (loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/computation/expressions.py'),
                               {'attrib-starts': [('_evaluate_standard|0|',
        61)],
                                'code-line': '        return op(a, b)\n',
                                'first-line': 52L,
                                'folded-linenos': [],
                                'sel-line': 68L,
                                'sel-line-start': 1536L,
                                'selection_end': 1536L,
                                'selection_start': 1536L,
                                'zoom': 0L}),
                              (loc('deepforest/main.py'),
                               {'attrib-starts': [('deepforest|0|',
        17),
        ('deepforest|0|.validation_step|0|',
         198)],
                                'code-line': '        return losses\n',
                                'first-line': 198L,
                                'folded-linenos': [],
                                'sel-line': 214L,
                                'sel-line-start': 8529L,
                                'selection_end': 8550L,
                                'selection_start': 8550L,
                                'zoom': 0L}),
                              (loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py'),
                               {'attrib-starts': [('Module|0|',
        177),
        ('Module|0|.__getattr__|0|',
         764)],
                                'code-line': "        raise ModuleAttributeE"\
        "rror(\"'{}' object has no attribute '{}'\".format(\n",
                                'first-line': 762L,
                                'folded-linenos': [],
                                'sel-line': 777L,
                                'sel-line-start': 32045L,
                                'selection_end': 32045L,
                                'selection_start': 32045L,
                                'zoom': 0L}),
                              (loc('deepforest/predict.py'),
                               {'attrib-starts': [('predict_file|0|',
        45)],
                                'code-line': '        prediction = model(ima'\
        'ge)        \n',
                                'first-line': 62L,
                                'folded-linenos': [],
                                'sel-line': 71L,
                                'sel-line-start': 2590L,
                                'selection_end': 2623L,
                                'selection_start': 2623L,
                                'zoom': 0L}),
                              (loc('deepforest/preprocess.py'),
                               {'attrib-starts': [('split_raster|0|',
        142)],
                                'code-line': '    file_path = image_basename'\
        ' + ".csv"\n',
                                'first-line': 233L,
                                'folded-linenos': [],
                                'sel-line': 242L,
                                'sel-line-start': 9412L,
                                'selection_end': 9451L,
                                'selection_start': 9451L,
                                'zoom': 0L}),
                              (loc('tests/test_main.py'),
                               {'attrib-starts': [('test_train_validation_st'\
        'ep|0|',
        43)],
                                'code-line': '    trainer.fit(m, train_ds, t'\
        'rain_ds)\n',
                                'first-line': 37L,
                                'folded-linenos': [],
                                'sel-line': 48L,
                                'sel-line-start': 1091L,
                                'selection_end': 1129L,
                                'selection_start': 1091L,
                                'zoom': 0L}),
                              (loc('tests/test_preprocess.py'),
                               {'attrib-starts': [('test_split_size_error|0|',
        127)],
                                'code-line': '                              '\
        '                     config["annotations_file"],\n',
                                'first-line': 57L,
                                'folded-linenos': [],
                                'sel-line': 130L,
                                'sel-line-start': 4463L,
                                'selection_end': 4541L,
                                'selection_start': 4541L,
                                'zoom': 0L}),
                              (loc('deepforest/utilities.py'),
                               {'attrib-starts': [('shapefile_to_annotations'\
        '|0|',
        162)],
                                'code-line': '        resolution = src.res[0'\
        ']\n',
                                'first-line': 173L,
                                'folded-linenos': [],
                                'sel-line': 181L,
                                'sel-line-start': 5736L,
                                'selection_end': 5766L,
                                'selection_start': 5766L,
                                'zoom': 0L})],
        'has-focus': False,
        'locked': False},
        [loc('../NeonTreeEvaluation/annotations/ABBY_063.xml'),
         loc('../DeepForest_Model/src/crops.py'),
         loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/computation/expressions.py'),
         loc('deepforest/main.py'),
         loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py'),
         loc('deepforest/predict.py'),
         loc('deepforest/preprocess.py'),
         loc('tests/test_main.py'),
         loc('tests/test_preprocess.py'),
         loc('deepforest/utilities.py')]),
                               'open_files': [u'deepforest/preprocess.py',
        u'deepforest/utilities.py',
        u'tests/test_preprocess.py',
        u'../DeepForest_Model/src/crops.py',
        u'../NeonTreeEvaluation/annotations/ABBY_063.xml',
        u'../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/computation/expressions.py',
        u'tests/test_main.py',
        u'deepforest/main.py',
        u'deepforest/predict.py']},
        'saved_notebook_display': None,
        'split_percents': {0: 0.4044943820224719},
        'splits': 2,
        'tab_location': 'top',
        'traversal_pos': ((1,
                           2),
                          1613966163.27741),
        'user_data': {}},
                 'saved_notebook_display': None,
                 'split_percents': {0: 0.5},
                 'splits': 2,
                 'tab_location': 'left',
                 'traversal_pos': ((0,
                                    0),
                                   1607965912.374172),
                 'user_data': {}},
        'window-alloc': (0,
                         23,
                         1747,
                         1097)}]}
guimgr.recent-documents = [loc('deepforest/predict.py'),
                           loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py'),
                           loc('deepforest/main.py'),
                           loc('tests/test_main.py'),
                           loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/computation/expressions.py'),
                           loc('../DeepForest_Model/src/crops.py'),
                           loc('deepforest/preprocess.py')]
guimgr.visual-state = {loc('../../../../Applications/WingPro.app/Contents/Resources/src/testing/runners/run_pytest_xml.py'): {'a'\
        'ttrib-starts': [('RunInSingleDir|0|',
                          456)],
        'code-line': '        import pytest\n',
        'first-line': 454L,
        'folded-linenos': [],
        'sel-line': 466L,
        'sel-line-start': 16384L,
        'selection_end': 16405L,
        'selection_start': 16384L,
        'zoom': 0L},
                       loc('.travis.yml'): {'attrib-starts': [],
        'code-line': 'env: TRAVIS=true\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 460L,
        'selection_end': 476L,
        'selection_start': 476L,
        'zoom': 0L},
                       loc('_config.yml'): {'attrib-starts': [],
        'code-line': 'theme: jekyll-theme-slate',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('azure-pipelines.yml'): {'attrib-starts': [],
        'code-line': '  - script: |\n',
        'first-line': 20L,
        'folded-linenos': [],
        'sel-line': 33L,
        'sel-line-start': 799L,
        'selection_end': 812L,
        'selection_start': 812L,
        'zoom': 0L},
                       loc('deepforest/IoU.py'): {'attrib-starts': [('_overl'\
        'ap_|0|',
        16)],
        'code-line': '    for index in truth_polys.index:\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 20L,
        'sel-line-start': 661L,
        'selection_end': 665L,
        'selection_start': 665L,
        'zoom': 0L},
                       loc('deepforest/callbacks.py'): {'attrib-starts': [],
        'code-line': 'import pandas as pd        \n',
        'first-line': 9L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 239L,
        'selection_end': 258L,
        'selection_start': 258L,
        'zoom': 0L},
                       loc('deepforest/data/2019_YELL_2_528000_4978000_image_crop2.xml'): {'a'\
        'ttrib-starts': [],
        'code-line': '    <filename>2019_YELL_2_528000_4978000_image_crop2.p'\
                     'ng</filename>\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 39L,
        'selection_end': 95L,
        'selection_start': 95L,
        'zoom': 0L},
                       loc('deepforest/data/2019_YELL_2_541000_4977000_image_crop.tif'): {'a'\
        'ttrib-starts': [],
        'code-line': 'MM\0*\0\r',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/data/2019_YELL_2_541000_4977000_image_crop.xml'): {'a'\
        'ttrib-starts': [],
        'code-line': '    <filename>2019_YELL_2_541000_4977000_image_crop.pn'\
                     'g</filename>\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 39L,
        'selection_end': 94L,
        'selection_start': 94L,
        'zoom': 0L},
                       loc('deepforest/data/deepforest_config.yml'): {'attri'\
        'b-starts': [],
        'code-line': '### \n',
        'first-line': 26L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 1496L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/data/eval_example.csv'): {'attrib-sta'\
        'rts': [],
        'code-line': 'image_path,xmin,ymin,xmax,ymax,label\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/dataset.py'): {'attrib-starts': [],
        'code-line': 'During training, the model expects both the input tens'\
                     'ors, as well as a targets (list of dictionary), contai'\
                     'ning:\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 145L,
        'selection_end': 157L,
        'selection_start': 152L,
        'zoom': 0L},
                       loc('deepforest/deepforest.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/engine.py'): {'attrib-starts': [],
        'code-line': 'from coco_eval import CocoEvaluator\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 256L,
        'selection_end': 291L,
        'selection_start': 291L,
        'zoom': 0L},
                       loc('deepforest/evaluate.py'): {'attrib-starts': [('e'\
        'valuate|0|',
        52)],
        'code-line': '    Args:\n',
        'first-line': 58L,
        'folded-linenos': [],
        'sel-line': 56L,
        'sel-line-start': 2538L,
        'selection_end': 2547L,
        'selection_start': 2547L,
        'zoom': 0L},
                       loc('deepforest/model.py'): {'attrib-starts': [('crea'\
        'te_model|0|',
        13)],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 324L,
        'selection_end': 324L,
        'selection_start': 324L,
        'zoom': 0L},
                       loc('deepforest/predict.py'): {'attrib-starts': [('pr'\
        'edict_tile|0|',
        85)],
        'code-line': '                 use_soft_nms = False,\n',
        'first-line': 116L,
        'folded-linenos': [],
        'sel-line': 93L,
        'sel-line-start': 3326L,
        'selection_end': 3355L,
        'selection_start': 3355L,
        'zoom': 0L},
                       loc('deepforest/preprocess.py'): {'attrib-starts': [('p'\
        'reprocess_image|0|',
        14)],
        'code-line': 'def preprocess_image(image):   \n',
        'first-line': 188L,
        'folded-linenos': [],
        'sel-line': 14L,
        'sel-line-start': 299L,
        'selection_end': 319L,
        'selection_start': 303L,
        'zoom': 0L},
                       loc('deepforest/retinanet_train.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest/train.py'): {'attrib-starts': [('trai'\
        'n|0|',
        2)],
        'code-line': '        config: a deepforest config object\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 226L,
        'selection_end': 268L,
        'selection_start': 268L,
        'zoom': 0L},
                       loc('deepforest/training.py'): {'attrib-starts': [('r'\
        'un|0|',
        52)],
        'code-line': '    \n',
        'first-line': 79L,
        'folded-linenos': [],
        'sel-line': 90L,
        'sel-line-start': 3553L,
        'selection_end': 3557L,
        'selection_start': 3557L,
        'zoom': 0L},
                       loc('deepforest/training_utils.py'): {'attrib-starts': [('M'\
        'etricLogger|0|',
        144),
        ('MetricLogger|0|.synchronize_between_processes|0|',
         172)],
        'code-line': '        for meter in self.meters.values():\n',
        'first-line': 144L,
        'folded-linenos': [],
        'sel-line': 173L,
        'sel-line-start': 5085L,
        'selection_end': 5121L,
        'selection_start': 5121L,
        'zoom': 0L},
                       loc('deepforest/transforms.py'): {'attrib-starts': [('T'\
        'oTensor|0|',
        29),
        ('ToTensor|0|.__call__|0|',
         30)],
        'code-line': '        image = F.to_tensor(image).float()\n',
        'first-line': 13L,
        'folded-linenos': [],
        'sel-line': 31L,
        'sel-line-start': 904L,
        'selection_end': 945L,
        'selection_start': 945L,
        'zoom': 0L},
                       loc('deepforest/utilities.py'): {'attrib-starts': [('s'\
        'hapefile_to_annotations|0|',
        162)],
        'code-line': '    #Read shapefile\n',
        'first-line': 203L,
        'folded-linenos': [],
        'sel-line': 172L,
        'sel-line-start': 5520L,
        'selection_end': 5539L,
        'selection_start': 5539L,
        'zoom': 0L},
                       loc('deepforest/visualize.py'): {'attrib-starts': [],
        'code-line': '#Visualize module for plotting and handling prediction'\
                     's\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('deepforest_config.yml'): {'attrib-starts': [],
        'code-line': '    batch_size: 1\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 17L,
        'sel-line-start': 312L,
        'selection_end': 329L,
        'selection_start': 329L,
        'zoom': 0L},
                       loc('docs/conf.py'): {'attrib-starts': [],
        'code-line': '#!/usr/bin/env python\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('docs/training.md'): {'attrib-starts': [],
        'code-line': '# Training models\n',
        'first-line': 51L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('environment.yml'): {'attrib-starts': [],
        'code-line': '  - pytorch_lightning\n',
        'first-line': 3L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 235L,
        'selection_end': 256L,
        'selection_start': 256L,
        'zoom': 0L},
                       loc('evaluate.py'): {'attrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 12L,
        'selection_start': 12L,
        'zoom': 0L},
                       loc('main.py'): {'attrib-starts': [('deepforest|0|',
        7),
        ('deepforest|0|.__init__|0|',
         10)],
        'code-line': '        # if not use installed.\n',
        'first-line': 120L,
        'folded-linenos': [],
        'sel-line': 12L,
        'sel-line-start': 413L,
        'selection_end': 444L,
        'selection_start': 444L,
        'zoom': 0L},
                       loc('requirements.txt'): {'attrib-starts': [],
        'code-line': 'tqdm\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 22L,
        'sel-line-start': 225L,
        'selection_end': 229L,
        'selection_start': 229L,
        'zoom': 0L},
                       loc('setup.py'): {'attrib-starts': [],
        'code-line': '      install_requires=[\n',
        'first-line': 47L,
        'folded-linenos': [],
        'sel-line': 54L,
        'sel-line-start': 1699L,
        'selection_end': 1723L,
        'selection_start': 1723L,
        'zoom': 0L},
                       loc('tests/test_data.py'): {'attrib-starts': [],
        'code-line': '# test data locations and existance\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_dataset.py'): {'attrib-starts': [('te'\
        'st_TreeDataset_transform|0|',
        24)],
        'code-line': '                             transforms=dataset.get_tr'\
                     'ansform(train=train))\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 29L,
        'sel-line-start': 913L,
        'selection_end': 960L,
        'selection_start': 953L,
        'zoom': 0L},
                       loc('tests/test_deepforest.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_environment.py'): {'attrib-starts': [('t'\
        'est_environment|0|',
        3)],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 123L,
        'selection_end': 123L,
        'selection_start': 123L,
        'zoom': 0L},
                       loc('tests/test_keras_retinanet.py'): {'attrib-starts': [],
        'code-line': '# test loading of keras retinanet\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 33L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_main.py'): {'attrib-starts': [('test_'\
        'predict_tile|0|',
        77)],
        'code-line': '    #test raster prediction \n',
        'first-line': 63L,
        'folded-linenos': [],
        'sel-line': 78L,
        'sel-line-start': 2387L,
        'selection_end': 2415L,
        'selection_start': 2415L,
        'zoom': 0L},
                       loc('tests/test_model.py'): {'attrib-starts': [('test'\
        '_load_backbone|0|',
        5)],
        'code-line': '',
        'first-line': 1L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 230L,
        'selection_end': 230L,
        'selection_start': 230L,
        'zoom': 0L},
                       loc('tests/test_preprocess.py'): {'attrib-starts': [('t'\
        'est_split_large_tile|0|',
        134)],
        'code-line': 'def test_split_large_tile(tmpdir):\n',
        'first-line': 132L,
        'folded-linenos': [],
        'sel-line': 134L,
        'sel-line-start': 4691L,
        'selection_end': 4720L,
        'selection_start': 4720L,
        'zoom': 0L},
                       loc('tests/test_tfrecords.py'): {'attrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('tests/test_utilities.py'): {'attrib-starts': [('t'\
        'est_xml_to_annotations|0|',
        18)],
        'code-line': '    #release_tag, weights = utilities.use_release()\n',
        'first-line': 18L,
        'folded-linenos': [],
        'sel-line': 30L,
        'sel-line-start': 678L,
        'selection_end': 729L,
        'selection_start': 729L,
        'zoom': 0L},
                       loc('tests/test_visualize.py'): {'attrib-starts': [('m'\
        '|0|',
        9)],
        'code-line': '    m.load_dataset(csv_file=csv_file, root_dir=os.path'\
                     '.dirname(csv_file), train=True)\n',
        'first-line': 7L,
        'folded-linenos': [],
        'sel-line': 15L,
        'sel-line-start': 320L,
        'selection_end': 370L,
        'selection_start': 370L,
        'zoom': 0L},
                       loc('../DeepForest/deepforest/deepforest.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'from deepforest.retinanet_train import main as retinan'\
                     'et_train\n',
        'first-line': 20L,
        'folded-linenos': [],
        'sel-line': 26L,
        'sel-line-start': 631L,
        'selection_end': 662L,
        'selection_start': 662L,
        'zoom': 0L},
                       loc('../DeepForest/tests/test_deepforest.py'): {'attr'\
        'ib-starts': [],
        'code-line': '#!/usr/bin/env python\n',
        'first-line': 6L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../DeepForest_Model/callbacks.py'): {'attrib-sta'\
        'rts': [('comet_callbacks|0|',
                 4),
                ('comet_callbacks|0|.on_epoch_end|0|',
                 19)],
        'code-line': '        \n',
        'first-line': 2L,
        'folded-linenos': [],
        'sel-line': 24L,
        'sel-line-start': 803L,
        'selection_end': 811L,
        'selection_start': 811L,
        'zoom': 0L},
                       loc('../DeepForest_Model/pretraining.py'): {'attrib-s'\
        'tarts': [],
        'code-line': 'from callbacks import comet_callbacks\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 1L,
        'sel-line-start': 28L,
        'selection_end': 65L,
        'selection_start': 50L,
        'zoom': 0L},
                       loc('../DeepForest_Model/src/crops.py'): {'attrib-sta'\
        'rts': [('shapefile_to_annotations|0|',
                 16)],
        'code-line': 'def shapefile_to_annotations(shapefile, rgb, savedir="'\
                     '."):\n',
        'first-line': 47L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 326L,
        'selection_end': 2134L,
        'selection_start': 326L,
        'zoom': 0L},
                       loc('../DeepForest_Model/tests/test_generate.py'): {'a'\
        'ttrib-starts': [('test_shapefile_to_annotations|0|',
                          6)],
        'code-line': '    df = crops.shapefile_to_annotations(shapefile="/Us'\
                     'ers/benweinstein/Downloads/temp_training/2019_OSBS_5_4'\
                     '10000_3282000_image_crop.shp", rgb="/Users/benweinstei'\
                     'n/Downloads/temp_training/2019_OSBS_5_410000_3282000_i'\
                     'mage_crop.tif")\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 142L,
        'selection_end': 1008L,
        'selection_start': 142L,
        'zoom': 0L},
                       loc('../DeepTreeAttention/tests/test_trees.py'): {'at'\
        'trib-starts': [],
        'code-line': "is_travis = 'TRAVIS' in os.environ\n",
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 124L,
        'selection_end': 349L,
        'selection_start': 124L,
        'zoom': 0L},
                       loc('../NeonTreeEvaluation_python/src/get_data.py'): {'a'\
        'ttrib-starts': [('load_ground_truth|0|',
                          47)],
        'code-line': '    geo_ground_truth = utilities.project_boxes(ground_'\
                     'truth)\n',
        'first-line': 39L,
        'folded-linenos': [],
        'sel-line': 53L,
        'sel-line-start': 1938L,
        'selection_end': 1998L,
        'selection_start': 1961L,
        'zoom': 0L},
                       loc('../deepforest-feedstock/conda-forge.yml'): {'att'\
        'rib-starts': [],
        'code-line': 'conda_forge_output_validation: true\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../deepforest-feedstock/recipe/meta.yaml'): {'at'\
        'trib-starts': [],
        'code-line': '    - tensorflow ==1.14.0\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 48L,
        'sel-line-start': 962L,
        'selection_end': 987L,
        'selection_start': 987L,
        'zoom': 0L},
                       loc('../vision/references/classification/train.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 39L,
        'selection_end': 49L,
        'selection_start': 49L,
        'zoom': 0L},
                       loc('../vision/references/classification/train_quantization.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import copy\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 38L,
        'selection_end': 38L,
        'selection_start': 38L,
        'zoom': 0L},
                       loc('../vision/references/classification/utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 141L,
        'selection_end': 141L,
        'selection_start': 141L,
        'zoom': 0L},
                       loc('../vision/references/detection/coco_eval.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import json\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/detection/coco_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import copy\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/detection/engine.py'): {'at'\
        'trib-starts': [('_get_iou_types|0|',
                         57)],
        'code-line': '    if isinstance(model, torch.nn.parallel.Distributed'\
                     'DataParallel):\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 59L,
        'sel-line-start': 1810L,
        'selection_end': 1844L,
        'selection_start': 1841L,
        'zoom': 0L},
                       loc('../vision/references/detection/group_by_aspect_ratio.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import bisect\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/detection/train.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import torchvision\n',
        'first-line': 2L,
        'folded-linenos': [],
        'sel-line': 25L,
        'sel-line-start': 952L,
        'selection_end': 952L,
        'selection_start': 952L,
        'zoom': 0L},
                       loc('../vision/references/detection/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 1L,
        'sel-line-start': 14L,
        'selection_end': 14L,
        'selection_start': 14L,
        'zoom': 0L},
                       loc('../vision/references/detection/utils.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import errno\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 133L,
        'selection_end': 145L,
        'selection_start': 145L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/coco_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from pycocotools import mask as coco_mask\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 102L,
        'selection_end': 115L,
        'selection_start': 115L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/train.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch.utils.data\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 52L,
        'selection_end': 61L,
        'selection_start': 61L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import random\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 41L,
        'selection_end': 46L,
        'selection_start': 46L,
        'zoom': 0L},
                       loc('../vision/references/segmentation/utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import defaultdict, deque\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/similarity/loss.py'): {'att'\
        'rib-starts': [],
        'code-line': "'''\n",
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 128L,
        'selection_end': 131L,
        'selection_start': 131L,
        'zoom': 0L},
                       loc('../vision/references/similarity/model.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import torch.nn as nn\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/similarity/sampler.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 108L,
        'selection_end': 108L,
        'selection_start': 108L,
        'zoom': 0L},
                       loc('../vision/references/similarity/test.py'): {'att'\
        'rib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 179L,
        'selection_end': 179L,
        'selection_start': 179L,
        'zoom': 0L},
                       loc('../vision/references/similarity/train.py'): {'at'\
        'trib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 184L,
        'selection_end': 184L,
        'selection_start': 184L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/scheduler.py'): {'a'\
        'ttrib-starts': [('WarmupMultiStepLR|0|',
                          4)],
        'code-line': 'class WarmupMultiStepLR(torch.optim.lr_scheduler._LRSc'\
                     'heduler):\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 47L,
        'selection_end': 88L,
        'selection_start': 88L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/train.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torch.utils.data.dataloader import default_collat'\
                     'e\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 75L,
        'selection_end': 91L,
        'selection_start': 91L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/references/video_classification/utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import defaultdict, deque\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/caltech.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/celeba.py'): {'at'\
        'trib-starts': [],
        'code-line': 'from functools import partial\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/cifar.py'): {'att'\
        'rib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/cityscapes.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from typing import Any, Callable, Dict, List, Optional'\
                     ', Union, Tuple\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 57L,
        'selection_end': 57L,
        'selection_start': 57L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/coco.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'from .vision import VisionDataset\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/fakedata.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/flickr.py'): {'at'\
        'trib-starts': [],
        'code-line': 'from collections import defaultdict\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/folder.py'): {'at'\
        'trib-starts': [],
        'code-line': 'from .vision import VisionDataset\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/hmdb51.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import glob\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/imagenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import tempfile\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 78L,
        'selection_end': 93L,
        'selection_start': 93L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/kinetics.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from .utils import list_dir\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/lsun.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'import string\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 91L,
        'selection_end': 104L,
        'selection_start': 104L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/mnist.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 72L,
        'selection_end': 81L,
        'selection_start': 81L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/omniglot.py'): {'a'\
        'ttrib-starts': [('Omniglot|0|',
                          7)],
        'code-line': '            creates from the "evaluation" set. This te'\
                     'rminology is defined by the authors.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 13L,
        'sel-line-start': 537L,
        'selection_end': 601L,
        'selection_start': 601L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/phototour.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 115L,
        'selection_end': 127L,
        'selection_start': 127L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/places365.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/sbd.py'): {'attri'\
        'b-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/sbu.py'): {'attri'\
        'b-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/semeion.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/stl10.py'): {'att'\
        'rib-starts': [],
        'code-line': 'from PIL import Image\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/svhn.py'): {'attr'\
        'ib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 215L,
        'selection_end': 215L,
        'selection_start': 215L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/ucf101.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import os\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/usps.py'): {'attr'\
        'ib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 175L,
        'selection_end': 175L,
        'selection_start': 175L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/utils.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import tarfile\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 52L,
        'selection_end': 52L,
        'selection_start': 52L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/video_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '    _read_video_from_file,\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 9L,
        'sel-line-start': 168L,
        'selection_end': 194L,
        'selection_start': 194L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/vision.py'): {'at'\
        'trib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 112L,
        'selection_end': 112L,
        'selection_start': 112L,
        'zoom': 0L},
                       loc('../vision/torchvision/datasets/voc.py'): {'attri'\
        'b-starts': [],
        'code-line': 'from .utils import download_url, verify_str_arg\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 7L,
        'sel-line-start': 197L,
        'selection_end': 228L,
        'selection_start': 228L,
        'zoom': 0L},
                       loc('../vision/torchvision/io/image.py'): {'attrib-st'\
        'arts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 5L,
        'sel-line-start': 73L,
        'selection_end': 73L,
        'selection_start': 73L,
        'zoom': 0L},
                       loc('../vision/torchvision/io/video.py'): {'attrib-st'\
        'arts': [],
        'code-line': '        av = ImportError(\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 329L,
        'selection_end': 354L,
        'selection_start': 354L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/alexnet.py'): {'att'\
        'rib-starts': [],
        'code-line': 'model_urls = {\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 9L,
        'sel-line-start': 139L,
        'selection_end': 153L,
        'selection_start': 153L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/densenet.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import re\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/anchor_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '# Copyright (c) Facebook, Inc. and its affiliates. All'\
                     ' Rights Reserved.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/backbone_utils.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/faster_rcnn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch.nn.functional as F\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 4L,
        'sel-line-start': 71L,
        'selection_end': 102L,
        'selection_start': 102L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/generalized_rcnn.py'): {'a'\
        'ttrib-starts': [('GeneralizedRCNN|0|',
                          12),
                         ('GeneralizedRCNN|0|.eager_outputs|0|',
                          35)],
        'code-line': '        # type: (Dict[str, Tensor], List[Dict[str, Ten'\
                     'sor]]) -> Union[Dict[str, Tensor], List[Dict[str, Tens'\
                     'or]]]\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 36L,
        'sel-line-start': 1056L,
        'selection_end': 1113L,
        'selection_start': 1107L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/image_list.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '# Copyright (c) Facebook, Inc. and its affiliates. All'\
                     ' Rights Reserved.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/keypoint_rcnn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torchvision.ops import MultiScaleRoIAlign\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 35L,
        'selection_end': 81L,
        'selection_start': 81L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/mask_rcnn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '__all__ = [\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 12L,
        'sel-line-start': 307L,
        'selection_end': 318L,
        'selection_start': 318L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/retinanet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from typing import Dict, List, Tuple, Optional\n',
        'first-line': 3L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 107L,
        'selection_end': 153L,
        'selection_start': 145L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/roi_heads.py'): {'a'\
        'ttrib-starts': [('RoIHeads|0|',
                          484),
                         ('RoIHeads|0|.check_targets|0|',
                          619)],
        'code-line': '        # type: (Optional[List[Dict[str, Tensor]]]) ->'\
                     ' None\n',
        'first-line': 607L,
        'folded-linenos': [],
        'sel-line': 620L,
        'sel-line-start': 22884L,
        'selection_end': 22909L,
        'selection_start': 22901L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/rpn.py'): {'a'\
        'ttrib-starts': [('RegionProposalNetwork|0|',
                          103),
                         ('RegionProposalNetwork|0|.pre_nms_top_n|0|',
                          167)],
        'code-line': '    def pre_nms_top_n(self):\n',
        'first-line': 157L,
        'folded-linenos': [],
        'sel-line': 167L,
        'sel-line-start': 6362L,
        'selection_end': 6379L,
        'selection_start': 6379L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/detection/transform.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 6L,
        'sel-line-start': 157L,
        'selection_end': 157L,
        'selection_start': 157L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/googlenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/inception.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import namedtuple\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/mnasnet.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/mobilenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 3L,
        'sel-line-start': 90L,
        'selection_end': 90L,
        'selection_start': 90L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/mobilenetv2.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torch import nn\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/resnet.py'): {'attr'\
        'ib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/segmentation/deeplabv3.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/segmentation/fcn.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from torch import nn\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/segmentation/segmentation.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 8L,
        'sel-line-start': 279L,
        'selection_end': 279L,
        'selection_start': 279L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/shufflenetv2.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/squeezenet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/utils.py'): {'attri'\
        'b-starts': [],
        'code-line': 'try:\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/vgg.py'): {'attrib-'\
        'starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/models/video/resnet.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from ..utils import load_state_dict_from_url\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 2L,
        'sel-line-start': 23L,
        'selection_end': 69L,
        'selection_start': 31L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/_box_convert.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/_register_onnx_ops.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import sys\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/_utils.py'): {'attrib-'\
        'starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/boxes.py'): {'attrib-s'\
        'tarts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/deform_conv.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import math\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/feature_pyramid_network.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from collections import OrderedDict\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/focal_loss.py'): {'att'\
        'rib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/misc.py'): {'attrib-st'\
        'arts': [],
        'code-line': '\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 14L,
        'sel-line-start': 328L,
        'selection_end': 328L,
        'selection_start': 328L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/poolers.py'): {'attrib'\
        '-starts': [],
        'code-line': '# Copyright (c) Facebook, Inc. and its affiliates. All'\
                     ' Rights Reserved.\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/ps_roi_align.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/ps_roi_pool.py'): {'at'\
        'trib-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/roi_align.py'): {'attr'\
        'ib-starts': [('roi_align|0|',
                       10)],
        'code-line': 'def roi_align(\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 10L,
        'sel-line-start': 260L,
        'selection_end': 274L,
        'selection_start': 274L,
        'zoom': 0L},
                       loc('../vision/torchvision/ops/roi_pool.py'): {'attri'\
        'b-starts': [],
        'code-line': 'import torch\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/autoaugment.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import math\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/functional.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import math\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/functional_pil.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import numbers\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/functional_tensor.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'import warnings\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../vision/torchvision/transforms/transforms.py'): {'a'\
        'ttrib-starts': [],
        'code-line': 'from .functional import InterpolationMode, _interpolat'\
                     'ion_modes_from_int\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 16L,
        'sel-line-start': 271L,
        'selection_end': 312L,
        'selection_start': 295L,
        'zoom': 0L},
                       loc('../../Downloads/tv-training-code.py'): {'attrib-'\
        'starts': [],
        'code-line': 'from engine import train_one_epoch, evaluate\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 12L,
        'sel-line-start': 372L,
        'selection_end': 383L,
        'selection_start': 377L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest/lib/python3.7/site-packages/_pytest/config/__init__.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest/lib/python3.7/site-packages/_pytest/python.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.7/site-packages/_pytest/python.py'): {'a'\
        'ttrib-starts': [],
        'code-line': '',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 0L,
        'sel-line-start': 0L,
        'selection_end': 0L,
        'selection_start': 0L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/outcomes.py'): {'a'\
        'ttrib-starts': [('fail|0|',
                          142)],
        'code-line': '    raise Failed(msg=msg, pytrace=pytrace)\n',
        'first-line': 142L,
        'folded-linenos': [],
        'sel-line': 152L,
        'sel-line-start': 4855L,
        'selection_end': 4855L,
        'selection_start': 4855L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/_pytest/python.py'): {'a'\
        'ttrib-starts': [('Module|0|',
                          495),
                         ('Module|0|._importtestmodule|0|',
                          573)],
        'code-line': '            raise self.CollectError(\n',
        'first-line': 594L,
        'folded-linenos': [],
        'sel-line': 602L,
        'sel-line-start': 22763L,
        'selection_end': 22799L,
        'selection_start': 22763L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/indexes/range.py'): {'a'\
        'ttrib-starts': [('RangeIndex|0|',
                          37),
                         ('RangeIndex|0|.get_loc|0|',
                          345)],
        'code-line': '                    raise KeyError(key) from err\n',
        'first-line': 337L,
        'folded-linenos': [],
        'sel-line': 352L,
        'sel-line-start': 9857L,
        'selection_end': 9857L,
        'selection_start': 9857L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/indexing.py'): {'a'\
        'ttrib-starts': [('_LocationIndexer|0|',
                          596),
                         ('_LocationIndexer|0|.__getitem__|0|',
                          880)],
        'code-line': '            return self._getitem_tuple(key)\n',
        'first-line': 882L,
        'folded-linenos': [],
        'sel-line': 887L,
        'sel-line-start': 27993L,
        'selection_end': 27993L,
        'selection_start': 27993L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/core/reshape/concat.py'): {'a'\
        'ttrib-starts': [('_Concatenator|0|',
                          300),
                         ('_Concatenator|0|.__init__|0|',
                          305)],
        'code-line': '        if isinstance(objs, (ABCSeries, ABCDataFrame, '\
                     'str)):\n',
        'first-line': 294L,
        'folded-linenos': [],
        'sel-line': 318L,
        'sel-line-start': 9054L,
        'selection_end': 9114L,
        'selection_start': 9114L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pandas/io/common.py'): {'a'\
        'ttrib-starts': [('_is_binary_mode|0|',
                          823)],
        'code-line': '    return isinstance(handle, tuple(binary_classes)) o'\
                     'r "b" in getattr(\n',
        'first-line': 811L,
        'folded-linenos': [],
        'sel-line': 828L,
        'sel-line-start': 26969L,
        'selection_end': 26969L,
        'selection_start': 26969L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py'): {'a'\
        'ttrib-starts': [('TrainLoop|0|',
                          37),
                         ('TrainLoop|0|.run_training_batch|0|',
                          641),
                         ('TrainLoop|0|.run_training_batch|0|.train_step_and'\
                          '_backward_closure|0|',
                          706)],
        'code-line': '                            result = self.training_ste'\
                     'p_and_backward(\n',
        'first-line': 692L,
        'folded-linenos': [],
        'sel-line': 707L,
        'sel-line-start': 29056L,
        'selection_end': 29056L,
        'selection_start': 29056L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/tifffile/tifffile.py'): {'a'\
        'ttrib-starts': [('TiffPage|0|',
                          5228),
                         ('TiffPage|0|.decode|0|',
                          5577),
                         ('TiffPage|0|.decode|0|.decode|1|',
                          5925)],
        'code-line': "                raise ValueError(f'TiffPage {self.inde"\
                     "x}: {exc}')\r\n",
        'first-line': 5612L,
        'folded-linenos': [],
        'sel-line': 5633L,
        'sel-line-start': 217235L,
        'selection_end': 217235L,
        'selection_start': 217235L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py'): {'a'\
        'ttrib-starts': [('Conv2d|0|',
                          261),
                         ('Conv2d|0|._conv_forward|0|',
                          413)],
        'code-line': '        return F.conv2d(input, weight, self.bias, self'\
                     '.stride,\n',
        'first-line': 395L,
        'folded-linenos': [],
        'sel-line': 418L,
        'sel-line-start': 18107L,
        'selection_end': 18107L,
        'selection_start': 18107L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/optim/sgd.py'): {'a'\
        'ttrib-starts': [('SGD|0|',
                          4),
                         ('SGD|0|.step|0|',
                          75)],
        'code-line': '                loss = closure()\n',
        'first-line': 68L,
        'folded-linenos': [],
        'sel-line': 85L,
        'sel-line-start': 3243L,
        'selection_end': 3243L,
        'selection_start': 3243L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py'): {'a'\
        'ttrib-starts': [('default_collate|0|',
                          41)],
        'code-line': '        return {key: default_collate([d[key] for d in '\
                     'batch]) for key in elem}\n',
        'first-line': 52L,
        'folded-linenos': [],
        'sel-line': 72L,
        'sel-line-start': 2926L,
        'selection_end': 2926L,
        'selection_start': 2926L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py'): {'a'\
        'ttrib-starts': [('_BaseDatasetFetcher|0|',
                          6),
                         ('_BaseDatasetFetcher|0|.fetch|0|',
                          13)],
        'code-line': '        raise NotImplementedError()\n',
        'first-line': 0L,
        'folded-linenos': [],
        'sel-line': 14L,
        'sel-line-start': 511L,
        'selection_end': 546L,
        'selection_start': 546L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchsummary/torchsummary.py'): {'a'\
        'ttrib-starts': [('summary|0|',
                          8),
                         ('summary|0|.register_hook|0|',
                          10),
                         ('summary|0|.register_hook|0|.hook|0|',
                          12)],
        'code-line': '            summary[m_key]["input_shape"] = list(input'\
                     '[0].size())\n',
        'first-line': 9L,
        'folded-linenos': [],
        'sel-line': 18L,
        'sel-line-start': 482L,
        'selection_end': 482L,
        'selection_start': 482L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/retinanet.py'): {'a'\
        'ttrib-starts': [('RetinaNet|0|',
                          243),
                         ('RetinaNet|0|.forward|0|',
                          483)],
        'code-line': '                boxes = target["boxes"]\n',
        'first-line': 498L,
        'folded-linenos': [],
        'sel-line': 503L,
        'sel-line-start': 21936L,
        'selection_end': 21936L,
        'selection_start': 21936L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/models/detection/transform.py'): {'a'\
        'ttrib-starts': [('GeneralizedRCNNTransform|0|',
                          57),
                         ('GeneralizedRCNNTransform|0|.normalize|0|',
                          119)],
        'code-line': '    def normalize(self, image):\n',
        'first-line': 108L,
        'folded-linenos': [],
        'sel-line': 119L,
        'sel-line-start': 4685L,
        'selection_end': 4716L,
        'selection_start': 4716L,
        'zoom': 0L},
                       loc('../../opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py'): {'a'\
        'ttrib-starts': [('Resize|0|',
                          231),
                         ('Resize|0|.__init__|0|',
                          249)],
        'code-line': '            raise ValueError("If size is a sequence, i'\
                     't should have 1 or 2 values")\n',
        'first-line': 233L,
        'folded-linenos': [],
        'sel-line': 254L,
        'sel-line-start': 9069L,
        'selection_end': 9152L,
        'selection_start': 9069L,
        'zoom': 0L}}
proj.build-cmd = {None: ('default',
                         None)}
proj.env-vars = {None: ('default',
                        [u''])}
proj.initial-dir = {None: ('custom',
                           u'/Users/benweinstein/Documents/DeepForest-pytorch')}
proj.pyexec = {None: ('custom',
                      u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/bin/python3')}
proj.pypath = {None: ('custom',
                      [])}
proj.vcs-system-config = ('prefs',
                          {'bzr': {'versioncontrol.bzr.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.bzr.executable': u'bzr'},
                           'cvs': {'versioncontrol.cvs.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.cvs.executable': u'cvs',
                                   'versioncontrol.cvs.extra-global-args': '-'\
        'z3'},
                           'git': {'versioncontrol.git.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.git.executable': u'git',
                                   'versioncontrol.git.use-porcelain': True},
                           'hg': {'versioncontrol.hg.active': 'active-if-pro'\
        'ject-dir',
                                  'versioncontrol.hg.dont-find-unregistered': True,
                                  'versioncontrol.hg.executable': u'hg',
                                  'versioncontrol.hg.extra-global-args': '--'\
        'encoding=utf8'},
                           'perforce': {'versioncontrol.perforce.active': 'n'\
        'ot-active',
        'versioncontrol.perforce.dont-find-unregistered': True,
        'versioncontrol.perforce.executable': u'p4',
        'versioncontrol.perforce.extra-global-args': ''},
                           'svn': {'versioncontrol.svn.active': 'active-if-p'\
        'roject-dir',
                                   'versioncontrol.svn.executable': u'svn',
                                   'versioncontrol.svn.extra-global-args': '',
                                   'versioncontrol.svn.svnadmin-executable': u'svnadmin'}})
search.search-history = [u'evaluate',
                         u'select_annotations',
                         u'epochs',
                         u'collate',
                         u'forward',
                         u'debug',
                         u'print_',
                         u'soft_nms',
                         u'self',
                         u'probability_threshold',
                         u'read_config',
                         u'load_dataset',
                         u'plt',
                         u'name',
                         u'show',
                         u'gpd',
                         u'os',
                         u'callback',
                         u'callbacks',
                         u'train']
testing.stored-results = (1,
                          [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_dataset.py',
                            [('test_TreeDataset_transform[True]',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              23),
                             ('test_TreeDataset',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              7),
                             ('test_TreeDataset_transform[False]',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              23)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_data.py',
                            [('test_get_data',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              7)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_utilities.py',
                            [('test_xml_to_annotations',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              18),
                             ('test_float_warning',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              33)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_model.py',
                            [('test_load_backbone',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              5)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_preprocess.py',
                            [('test_split_large_tile',
                              0,
                              None,
                              None,
                              None,
                              1613860604,
                              134),
                             ('test_split_raster',
                              0,
                              None,
                              None,
                              None,
                              1613859645,
                              76),
                             ('test_split_size_error',
                              0,
                              None,
                              None,
                              None,
                              1613859645,
                              127),
                             ('test_split_raster_empty',
                              0,
                              None,
                              None,
                              None,
                              1613859645,
                              87),
                             ('test_select_annotations_tile',
                              0,
                              None,
                              None,
                              None,
                              1613859645,
                              60),
                             ('test_compute_windows',
                              0,
                              None,
                              None,
                              None,
                              1613859645,
                              39),
                             ('test_select_annotations',
                              0,
                              None,
                              None,
                              None,
                              1613859645,
                              45)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                            [('test_train',
                              0,
                              None,
                              None,
                              None,
                              1613965807,
                              35),
                             ('test_main',
                              0,
                              None,
                              None,
                              None,
                              1613965807,
                              32),
                             ('test_precision_recall_callbacks',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=12>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 155,
                                 'test_precision_recall_callbacks',
                                 None,
                                 '    trainer.fit(m, train_ds)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 470,
                                 'fit',
                                 None,
                                 '        results = self.accelerator_backend'\
                                 '.train()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/accelerators/cpu_acce'\
                                 'lerator.py',
                                 62,
                                 'train',
                                 None,
                                 '        results = self.train_or_test()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/accelerators/accelera'\
                                 'tor.py',
                                 69,
                                 'train_or_test',
                                 None,
                                 '            results = self.trainer.train()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 521,
                                 'train',
                                 None,
                                 '                    self.train_loop.run_tr'\
                                 'aining_epoch()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/training_loop'\
                                 '.py',
                                 625,
                                 'run_training_epoch',
                                 None,
                                 '        self.run_on_epoch_end_hook(epoch_o'\
                                 'utput)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/training_loop'\
                                 '.py',
                                 856,
                                 'run_on_epoch_end_hook',
                                 None,
                                 "        self.trainer.call_hook('on_epoch_e"\
                                 "nd')"),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 887,
                                 'call_hook',
                                 None,
                                 '                trainer_hook(*args, **kwar'\
                                 'gs)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/callback_hook'\
                                 '.py',
                                 107,
                                 'on_epoch_end',
                                 None,
                                 '            callback.on_epoch_end(self, se'\
                                 'lf.get_model())'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/callbacks.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/callbacks.py',
                                 63,
                                 'on_epoch_end',
                                 None,
                                 '            self.log_predictions(pl_module'\
                                 ')'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/callbacks.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/callbacks.py',
                                 42,
                                 'log_predictions',
                                 None,
                                 '        predictions = predict.predict_file'\
                                 '(pl_module.backbone, self.csv_file, self.r'\
                                 'oot_dir, savedir=self.savedir)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 76,
                                 'predict_file',
                                 None,
                                 '        prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              147),
                             ('test_predict_return_plot',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=3>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 75,
                                 'test_predict_return_plot',
                                 None,
                                 '    plot = trained_model.predict_image(ima'\
                                 'ge = image, return_plot=True)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 91,
                                 'predict_image',
                                 None,
                                 '        result = predict.predict_image(mod'\
                                 'el =  self.backbone, image = image, return'\
                                 '_plot = return_plot, score_threshold = sco'\
                                 're_threshold, device=self.device)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 31,
                                 'predict_image',
                                 None,
                                 '    prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              71),
                             ('test_evaluate',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=4>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 125,
                                 'test_evaluate',
                                 None,
                                 '    precision, recall = m.evaluate(csv_fil'\
                                 'e, root_dir, iou_threshold = 0.5)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 243,
                                 'evaluate',
                                 None,
                                 '        predictions = self.predict_file(cs'\
                                 'v_file, root_dir)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 110,
                                 'predict_file',
                                 None,
                                 '        df = predict.predict_file(self.bac'\
                                 'kbone, csv_file, root_dir, save_dir)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 76,
                                 'predict_file',
                                 None,
                                 '        prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              121),
                             ('test_predict_image_fromarray',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=3>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 67,
                                 'test_predict_image_fromarray',
                                 None,
                                 '    prediction = trained_model.predict_ima'\
                                 'ge(image = image)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 91,
                                 'predict_image',
                                 None,
                                 '        result = predict.predict_image(mod'\
                                 'el =  self.backbone, image = image, return'\
                                 '_plot = return_plot, score_threshold = sco'\
                                 're_threshold, device=self.device)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 31,
                                 'predict_image',
                                 None,
                                 '    prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              63),
                             ('test_predict_image_empty',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=3>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 53,
                                 'test_predict_image_empty',
                                 None,
                                 '    prediction = m.predict_image(image = i'\
                                 'mage)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 91,
                                 'predict_image',
                                 None,
                                 '        result = predict.predict_image(mod'\
                                 'el =  self.backbone, image = image, return'\
                                 '_plot = return_plot, score_threshold = sco'\
                                 're_threshold, device=self.device)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 31,
                                 'predict_image',
                                 None,
                                 '    prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              50),
                             ('test_predict_tile',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=4>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 89,
                                 'test_predict_tile',
                                 None,
                                 '    prediction = trained_model.predict_til'\
                                 'e(raster_path = raster_path,'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 150,
                                 'predict_tile',
                                 None,
                                 '        result = predict.predict_tile('),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 147,
                                 'predict_tile',
                                 None,
                                 '        boxes = predict_image(model=model,'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 31,
                                 'predict_image',
                                 None,
                                 '    prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              85),
                             ('test_train_callbacks',
                              0,
                              None,
                              None,
                              None,
                              1613965807,
                              126),
                             ('test_train_validation_step',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo TypeError(\"isnan(): argument"\
                               " 'input' (position 1) must be Tensor, not di"\
                               "ct\") tblen=14>",
                               "TypeError: isnan(): argument 'input' (positi"\
                               "on 1) must be Tensor, not dict",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 49,
                                 'test_train_validation_step',
                                 None,
                                 '    trainer.fit(m, train_ds, train_ds)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 470,
                                 'fit',
                                 None,
                                 '        results = self.accelerator_backend'\
                                 '.train()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/accelerators/cpu_acce'\
                                 'lerator.py',
                                 62,
                                 'train',
                                 None,
                                 '        results = self.train_or_test()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/accelerators/accelera'\
                                 'tor.py',
                                 69,
                                 'train_or_test',
                                 None,
                                 '            results = self.trainer.train()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 521,
                                 'train',
                                 None,
                                 '                    self.train_loop.run_tr'\
                                 'aining_epoch()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/training_loop'\
                                 '.py',
                                 588,
                                 'run_training_epoch',
                                 None,
                                 '                self.trainer.run_evaluatio'\
                                 'n(test_mode=False)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 628,
                                 'run_evaluation',
                                 None,
                                 '        self.evaluation_loop.on_evaluation'\
                                 '_end()'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/evaluation_lo'\
                                 'op.py',
                                 111,
                                 'on_evaluation_end',
                                 None,
                                 "            self.trainer.call_hook('on_val"\
                                 "idation_end', *args, **kwargs)"),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/trainer.py',
                                 887,
                                 'call_hook',
                                 None,
                                 '                trainer_hook(*args, **kwar'\
                                 'gs)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/trainer/callback_hook'\
                                 '.py',
                                 177,
                                 'on_validation_end',
                                 None,
                                 '            callback.on_validation_end(sel'\
                                 'f, self.get_model())'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/callbacks/model_check'\
                                 'point.py',
                                 203,
                                 'on_validation_end',
                                 None,
                                 '        self.save_checkpoint(trainer, pl_m'\
                                 'odule)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/callbacks/model_check'\
                                 'point.py',
                                 248,
                                 'save_checkpoint',
                                 None,
                                 '            self._save_top_k_checkpoints(t'\
                                 'rainer, pl_module, monitor_candidates)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/callbacks/model_check'\
                                 'point.py',
                                 590,
                                 '_save_top_k_checkpoints',
                                 None,
                                 '            self._update_best_and_save(cur'\
                                 'rent, epoch, step, trainer, pl_module, met'\
                                 'rics)'),
                                (u'/Users/benweinstein/opt/miniconda3/envs/DeepForest_pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py',
                                 '/Users/benweinstein/opt/miniconda3/envs/De'\
                                 'epForest_pytorch/lib/python3.8/site-packag'\
                                 'es/pytorch_lightning/callbacks/model_check'\
                                 'point.py',
                                 616,
                                 '_update_best_and_save',
                                 None,
                                 '        if torch.isnan(current):')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              43),
                             ('test_predict_file',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=3>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 80,
                                 'test_predict_file',
                                 None,
                                 '    df = trained_model.predict_file(csv_fi'\
                                 'le, root_dir = os.path.dirname(csv_file), '\
                                 'save_dir=tmpdir)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 110,
                                 'predict_file',
                                 None,
                                 '        df = predict.predict_file(self.bac'\
                                 'kbone, csv_file, root_dir, save_dir)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 76,
                                 'predict_file',
                                 None,
                                 '        prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              77),
                             ('test_predict_image_fromfile',
                              1,
                              None,
                              None,
                              ('',
                               "<ExceptionInfo AttributeError(\"'list' objec"\
                               "t has no attribute 'to_device'\") tblen=3>",
                               "AttributeError: 'list' object has no attribu"\
                               "te 'to_device'",
                               [(u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/tests/test_main.py',
                                 59,
                                 'test_predict_image_fromfile',
                                 None,
                                 '    prediction = trained_model.predict_ima'\
                                 'ge(path = path)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/main.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/main.py',
                                 91,
                                 'predict_image',
                                 None,
                                 '        result = predict.predict_image(mod'\
                                 'el =  self.backbone, image = image, return'\
                                 '_plot = return_plot, score_threshold = sco'\
                                 're_threshold, device=self.device)'),
                                (u'/Users/benweinstein/Documents/DeepForest-pytorch/deepforest/predict.py',
                                 '/Users/benweinstein/Documents/DeepForest-p'\
                                 'ytorch/deepforest/predict.py',
                                 31,
                                 'predict_image',
                                 None,
                                 '    prediction.to_device("cpu")')],
                               0,
                               None,
                               None,
                               None,
                               None),
                              1613965807,
                              56)]),
                           (u'/Users/benweinstein/Documents/DeepForest-pytorch/tests/test_environment.py',
                            [('test_environment',
                              0,
                              None,
                              None,
                              None,
                              1613602013,
                              3)])],
                          {u'/Users/benweinstein/Documents/DeepForest/tests/test_deepforest.py': (u'Test process aborted: some tests were not run',
        1607966490)})
